WEBVTT

1
00:00:37.650 --> 00:00:50.430
Michael Shannon: Hello there and welcome back everybody to day to session two of the CIS SP boot camp with Michael and David it's great to have everybody back well, not everybody yet, but eventually.

2
00:00:52.050 --> 00:01:06.570
Michael Shannon: People are kind of virtually filing in the back door so we'll give them a few seconds, but welcome to everybody who's here, looking at some of the chat areas david's been very busy thanks man for doing all that.

3
00:01:11.400 --> 00:01:13.800
Michael Shannon: So Victor you watch the.

4
00:01:15.180 --> 00:01:16.950
Michael Shannon: CIS SP March.

5
00:01:18.210 --> 00:01:21.270
Michael Shannon: boot camp session one uh.

6
00:01:22.500 --> 00:01:24.270
Michael Shannon: Well, you can wait for.

7
00:01:26.580 --> 00:01:31.800
Michael Shannon: This boot camp session one and watch it, it is pretty much the same.

8
00:01:32.880 --> 00:01:35.730
Michael Shannon: None of the content has been changed.

9
00:01:37.050 --> 00:01:38.160
Michael Shannon: But you know.

10
00:01:40.440 --> 00:01:43.500
Michael Shannon: It should be pretty much similar.

11
00:01:45.030 --> 00:01:59.910
Michael Shannon: I can't think of anything, maybe you know, a couple of anecdotal comments or whatever might be different, but you know you might want to wait or after class today watch the may bootcamp session one.

12
00:02:00.960 --> 00:02:07.380
Michael Shannon: Evelyn can we also have the deck so the study guide.

13
00:02:08.460 --> 00:02:25.350
Michael Shannon: The PDF files, those are, in essence, the deck it's you know, an export into PDF of all of the PowerPoint slides we don't distribute the PowerPoint slides because that's really kind of intellectual property.

14
00:02:26.370 --> 00:02:28.080
Michael Shannon: That we use, you know to.

15
00:02:29.130 --> 00:02:36.630
Michael Shannon: teach the course but that P, the pdfs are pretty much all those slides.

16
00:02:40.380 --> 00:02:47.700
Michael Shannon: And as David is saying our session one recording should be up in Pacific to a little later today.

17
00:02:48.630 --> 00:03:08.460
Michael Shannon: So you know we usually say 24 hours after the courses over and technically speaking it's only been 20 hours, since the course was over right so usually later on in day two you'll have those available to you all right.

18
00:03:10.770 --> 00:03:22.980
Michael Shannon: alrighty let's go ahead today we've got a lot to cover we have 162 slides i'm going to go pretty quickly over this first section, which is really asset classification.

19
00:03:25.650 --> 00:03:33.630
Michael Shannon: And some of these other topics and get quickly to risk management so we've got risk management, which I want to spend some time on.

20
00:03:35.700 --> 00:03:36.870
Michael Shannon: there's also.

21
00:03:38.790 --> 00:03:49.200
Michael Shannon: Practical cryptography we're going to cover today when I first took the CIS SP back in 2002 and I took it again, you know 2015.

22
00:03:49.920 --> 00:03:59.640
Michael Shannon: There was actually a cryptography domain, so you know of the domains of the common body of knowledge and then they call it.

23
00:04:00.240 --> 00:04:12.870
Michael Shannon: For years, there was a dedicated cryptography domain, they no longer have that however cryptography practical of crop cryptography is really interleaved.

24
00:04:13.350 --> 00:04:27.240
Michael Shannon: through most of the other domains right, so we want to make sure that i've got a pretty big section on practical cryptography that we want to cover Okay, and then identity management.

25
00:04:28.440 --> 00:04:35.490
Michael Shannon: we're going to wrap up with today, so an important day, but these early these early slides i'm going to go pretty quickly through these.

26
00:04:36.090 --> 00:04:45.900
Michael Shannon: you're going to do a gap analysis right but uh just so make sure if there's anything in this asset classification asset assessment that.

27
00:04:46.290 --> 00:04:55.680
Michael Shannon: You know you make sure you review that before the exam and what's The bottom line here, well, the bottom line is before we get to the risk management and risk assessment.

28
00:04:57.540 --> 00:05:07.800
Michael Shannon: You have to know what you have right having an inventory of your physical and logical assets, knowing the things you're going to protect.

29
00:05:08.310 --> 00:05:19.980
Michael Shannon: With your controls is kind of part of the first order of business, yesterday we looked at, you know kind of global topics right ending up with like policies.

30
00:05:20.670 --> 00:05:29.370
Michael Shannon: So we have to know, we have the first thing here we just remind ourselves that there are three main states of data data at rest.

31
00:05:30.150 --> 00:05:42.840
Michael Shannon: or data in storage and we have different types of storage, we have data in transit, and we have different types of transit right we have wired transit on ethernet we have fiber.

32
00:05:43.290 --> 00:05:57.630
Michael Shannon: We have wireless different several different types of wireless transmission so data in motion data in use volatile data and, as I mentioned yesterday that's where we have the least maturity.

33
00:05:59.370 --> 00:06:08.880
Michael Shannon: As far as protection goes often we opt to not protect the data in us because of the overhead.

34
00:06:10.320 --> 00:06:34.200
Michael Shannon: But it's very common for content delivery networks like akamai or cloud flair or aws cloud front to distribute the copies of their content, not to these edge locations in raid arrays but in reddest clusters in memory storage memory chips clusters of memory chips.

35
00:06:35.310 --> 00:06:46.050
Michael Shannon: And therefore often there is no encryption of that data okay it's just cached content, but if we do decide to encrypt data.

36
00:06:47.520 --> 00:06:56.430
Michael Shannon: In use we'll talk about a couple of options in the cryptography section so obviously knowing the different States of data we protect data addressed.

37
00:06:57.210 --> 00:07:13.140
Michael Shannon: Right we're obviously going to store that data in zones right and the zone based methodology and those zones that have our raid arrays are our servers or a storage area networking or directly attached storage.

38
00:07:14.160 --> 00:07:31.470
Michael Shannon: We obviously have zone interface points of service firewalls between those zones so we're controlling the access to that data right with kind of perimeter offense perimeter defenses layer three for firewalls.

39
00:07:33.060 --> 00:07:34.770
Michael Shannon: intrusion prevention systems.

40
00:07:35.850 --> 00:07:43.590
Michael Shannon: database activity, monitoring and anti virus, we have our Defense in depth controls for access to that data.

41
00:07:45.120 --> 00:07:54.300
Michael Shannon: We want to make sure we have strict multifactor authentication separation of duties Okay, maybe do a low operator, maybe different.

42
00:07:54.750 --> 00:08:13.260
Michael Shannon: groups or users to do the backups in the snapshots and different groups to do the restoration recovery, we can have full disk encryption self encrypting drives data address could be keys and certificates that can be stored in hardware security modules.

43
00:08:14.880 --> 00:08:15.900
Michael Shannon: Data in motion.

44
00:08:17.250 --> 00:08:44.070
Michael Shannon: We can just dedicate align a leased line it could it be tapped yeah, but we can dedicate fiber we can do encapsulation techniques or we can use cryptographic methods, it will talk about later transport layer security usually 1.2 and 1.3 going forward IP SEC vpn site remote access.

45
00:08:45.930 --> 00:08:52.620
Michael Shannon: I version two traditionally or newer relatively newer ike i'm sorry I conversion one.

46
00:08:53.700 --> 00:09:10.650
Michael Shannon: Internet key exchange version one traditionally, which is still being used usually more often, like in branch offices and sites with older equipment and there's like version two which supports sweet the cryptography we'll talk about that.

47
00:09:11.790 --> 00:09:12.990
Michael Shannon: Data in motion.

48
00:09:14.250 --> 00:09:23.010
Michael Shannon: A lot of organizations now we're transitioning away from wpa two which we've used for 15 years or so.

49
00:09:24.090 --> 00:09:30.840
Michael Shannon: To wpa three that has management frame protection native or.

50
00:09:32.850 --> 00:09:38.370
Michael Shannon: Protected management frames you'll see both of those MSP and HP EMF.

51
00:09:39.630 --> 00:10:02.280
Michael Shannon: it's very common to use to protect data in motion and 802 dot one X ieee P neck port based access control with eXtensible authentication protocols dot one X works over a wireless network dot 11 dot one X works over a wired network.

52
00:10:03.810 --> 00:10:08.250
Michael Shannon: very popular it's a big part of google's zero trust initiative.

53
00:10:10.890 --> 00:10:32.430
Michael Shannon: And, along with it at the enterprise level various modes of eXtensible authentication protocol, we need to be familiar with a PT Ls AAP TT Ls protected AAP peep popular with Microsoft AAP fast popular with Cisco.

54
00:10:34.140 --> 00:10:35.490
Michael Shannon: And then another emerging.

55
00:10:37.650 --> 00:10:39.960
Michael Shannon: mechanism and that's really.

56
00:10:41.490 --> 00:10:42.540
Michael Shannon: that's a typo.

57
00:10:43.710 --> 00:10:46.620
Michael Shannon: So make sure that i'll make sure I fixed that.

58
00:10:48.810 --> 00:10:53.340
Michael Shannon: i'll make a new PDF for you, because that's not a.

59
00:10:56.190 --> 00:10:58.050
Michael Shannon: that's energy dot one at.

60
00:11:00.150 --> 00:11:00.510
Michael Shannon: Okay.

61
00:11:02.160 --> 00:11:15.840
Michael Shannon: And that's a MAC SEC so basically getting the same security services that we get from IP SEC at layer to media access control security, and you know encryption for confidentiality.

62
00:11:17.280 --> 00:11:21.870
Michael Shannon: And you can deploy a MAC SEC, without having to have a separate H MAC.

63
00:11:24.390 --> 00:11:30.540
Michael Shannon: Because you can deploy MAC SEC is an ad we'll talk more about that that's very popular solution in fact.

64
00:11:31.590 --> 00:11:36.030
Michael Shannon: More and more cloud providers that are offering these direct connections.

65
00:11:38.190 --> 00:11:56.700
Michael Shannon: aws direct connect express route Google interconnect these direct connections to cloud partners aren't including Max SEC to increase your level of competence that the data is protected, because it's the frames are being encrypted.

66
00:12:00.090 --> 00:12:07.560
Michael Shannon: So, again we're talking about the importance of knowing what you have right if you've ever had to.

67
00:12:08.610 --> 00:12:10.710
Michael Shannon: Do let's say an elaborate.

68
00:12:12.000 --> 00:12:22.500
Michael Shannon: home insurance policy or renters policy or maybe you've got a policy with your insurance company, and you have things you want to ensure, in your home.

69
00:12:22.860 --> 00:12:44.970
Michael Shannon: Often, what you have to do is go through, and like make an inventory of all of your valuables sometimes you take pictures, or you take video of all of your valuables and you provide that to the insurance company who's ensuring your collectibles your valuables in your home for the policy.

70
00:12:45.990 --> 00:12:56.640
Michael Shannon: same concept before you can lower risk and have a high degree of insurance, that you can protect your assets, you have to know what they are.

71
00:12:57.210 --> 00:13:12.180
Michael Shannon: You have to have some type of value on them either qualitatively, you know this is this is mission critical, and this is, you know important or quantitatively, preferably with real numbers.

72
00:13:14.070 --> 00:13:15.150
Michael Shannon: prioritisation.

73
00:13:17.130 --> 00:13:34.410
Michael Shannon: Classification labeling and the classification may be necessary, because the access control model mandates that you have sensitivity levels classification levels, whether you're in the public sector, the private sector.

74
00:13:35.970 --> 00:13:41.370
Michael Shannon: You may have a configuration management database it's going to store all this information.

75
00:13:42.930 --> 00:13:57.660
Michael Shannon: Hopefully, whatever schema you use to tag and label your physical and logical assets on premises that's a schema that you can also kind of translate or migrate to the cloud.

76
00:14:00.060 --> 00:14:02.880
Michael Shannon: it's always better if you're going to use the cloud.

77
00:14:04.320 --> 00:14:12.960
Michael Shannon: And if you're going to use the cloud for single sign on that you try to maintain let's say your usernames schema.

78
00:14:14.010 --> 00:14:23.100
Michael Shannon: Right in your directory if you can maintain that if you can maintain your key value pairs schema for your labeling and handling.

79
00:14:24.270 --> 00:14:39.840
Michael Shannon: It makes your hybrid cloud scenario, but a much smoother transition, otherwise you have to do, additional mapping, maybe you have to have middle tier services that you know, are going to do proxies.

80
00:14:43.980 --> 00:15:01.380
Michael Shannon: I mentioned service now as a potential see imdb but there's no specific that those are just there for you to go and research on your own, but this is a critical part of the change control changing configuration management practices.

81
00:15:03.750 --> 00:15:17.040
Michael Shannon: I I till but I till forbid call these practices, a critical role and it service management it sm whether you use an ideal for or co but five or something else.

82
00:15:19.020 --> 00:15:32.340
Michael Shannon: It just comes down to knowing what you have and having it stored and not just storing, but some type of inventory system that is dynamic and automated so you can on a.

83
00:15:33.510 --> 00:15:36.360
Michael Shannon: continual basis know the posture.

84
00:15:37.500 --> 00:15:40.590
Michael Shannon: As far as updates and upgrades and service packs.

85
00:15:41.820 --> 00:15:45.330
Michael Shannon: Next Generation software that's very important as well.

86
00:15:46.470 --> 00:15:50.580
Michael Shannon: extremely important in a zero trust environment.

87
00:15:51.600 --> 00:16:01.770
Michael Shannon: Because in zero trust it's not just knowing what you have, as far as the objects are your assets are concerned it's knowing at any given time, the posture.

88
00:16:03.840 --> 00:16:06.930
Michael Shannon: The state of those assets.

89
00:16:08.640 --> 00:16:09.960
Michael Shannon: So this database.

90
00:16:11.670 --> 00:16:23.250
Michael Shannon: is critical to to a wide variety of services patch management incident management problem management release and deployment all of these different IT services.

91
00:16:24.480 --> 00:16:46.260
Michael Shannon: It also is going to contribute to root cause analysis problem resolution it'll be using forensic investigations incident response teams will will use this it'll use for be used for formulating strategy capacity management availability management budgetary forecasting.

92
00:16:47.820 --> 00:17:00.960
Michael Shannon: So this database, whether it's something that's on premises, maybe a no sequel database, or some software as a service solution is critical to knowing what you have, and knowing this state of what you have.

93
00:17:03.270 --> 00:17:04.500
Michael Shannon: In your labeling.

94
00:17:05.640 --> 00:17:18.810
Michael Shannon: you're tagging your labeling has to have a consistent schema and it has to be something that can be useful to generate meaningful data metrics for a wide variety of services.

95
00:17:20.340 --> 00:17:22.350
Michael Shannon: And again, like I said it may be based on.

96
00:17:23.700 --> 00:17:26.010
Michael Shannon: sensitivity levels in a MAC model.

97
00:17:27.390 --> 00:17:29.100
Michael Shannon: Like a bell up a doula model.

98
00:17:30.240 --> 00:17:35.640
Michael Shannon: And there's different things that can you know dictate a classification level.

99
00:17:36.900 --> 00:17:47.430
Michael Shannon: You know, often is based on some architecture your subjects in your objects are being controlled by a mandatory access control model very common.

100
00:17:48.930 --> 00:18:00.630
Michael Shannon: But if you aren't using that model, other ways you'll classify it as basically value qualitatively and quantitatively the age right things assets.

101
00:18:01.200 --> 00:18:20.340
Michael Shannon: From a financial standpoint, you will deprecate right from an accountancy standpoint, the value of assets on maybe on an annual basis, goes down over you useful life, the utility and I mentioned the example yesterday.

102
00:18:22.380 --> 00:18:32.370
Michael Shannon: You know, in a couple of months i'm going to have to redo my certified cloud security professional.

103
00:18:33.390 --> 00:18:35.220
Michael Shannon: Is C squared certification.

104
00:18:37.170 --> 00:18:47.580
Michael Shannon: Because I just did it last summer, but they're changing the exam so all of that most of that content or some of that content it's useful life.

105
00:18:48.780 --> 00:18:52.830
Michael Shannon: will be deprecating as I replace it with the new course.

106
00:18:54.210 --> 00:19:14.670
Michael Shannon: And then it can be based on personally identifiable information or health information, whoever that particular individual is in the organization so some type of unified schema and often today that always we do gravitate towards a document key value.

107
00:19:15.750 --> 00:19:16.200
Michael Shannon: type.

108
00:19:18.270 --> 00:19:35.340
Michael Shannon: Does that mean we don't use relational database systems anymore absolutely not still quite widely deployed, but for a new implementation, you might want to gravitate towards a key value pair no sequel kind of approach.

109
00:19:38.040 --> 00:19:42.360
Michael Shannon: If you looked at the Google beyond corp which I recommended to you.

110
00:19:45.930 --> 00:19:50.490
Michael Shannon: When you go check it out, which is there zero trust initiative.

111
00:19:53.280 --> 00:20:06.420
Michael Shannon: They place a high value on their inventory system their automated inventory system that is tightly coupled with their directory service HR and other services.

112
00:20:06.870 --> 00:20:16.980
Michael Shannon: to know exactly what they have in the state of those assets, very important to them, because if you're taking an if you take an attribute based access control model.

113
00:20:18.510 --> 00:20:34.980
Michael Shannon: Yes, you have variables of the subjects, but the entities that are accessing the assets, those are variables, who, what, when why where how but there's also variables of the objects their state their posture.

114
00:20:36.270 --> 00:20:36.660
Michael Shannon: Okay.

115
00:20:38.550 --> 00:20:44.340
Michael Shannon: And that ties in a heavily that system and inventory system is being used.

116
00:20:45.600 --> 00:20:54.000
Michael Shannon: By their 802 dot one X environment to do remediation network access control.

117
00:20:55.590 --> 00:20:58.440
Michael Shannon: That has change of authorization built into it.

118
00:20:59.640 --> 00:21:09.330
Michael Shannon: So that if somebody tries to access the network and the posture of their device or the posture of whatever they're trying to access is that up to date.

119
00:21:09.990 --> 00:21:28.290
Michael Shannon: Then they're going to be moved or quarantined maybe get a captive portal, or something to remediate and then change of authorization will say okay now, you can have access to the directory service or now, you can have access to the corporate land or the wireless network or whatever.

120
00:21:29.940 --> 00:21:31.440
Michael Shannon: A key aspect of.

121
00:21:32.610 --> 00:21:34.620
Michael Shannon: Port based network access control.

122
00:21:36.420 --> 00:21:43.770
Michael Shannon: So you may have a digital asset manager that's a growing enterprise role, especially as we use cloud.

123
00:21:45.450 --> 00:21:47.670
Michael Shannon: cloud providers solutions.

124
00:21:49.440 --> 00:21:51.660
Michael Shannon: It used to be, I would say.

125
00:21:54.030 --> 00:21:55.860
Michael Shannon: When those courses being developed.

126
00:21:57.270 --> 00:22:00.690
Michael Shannon: In the objectives they specifically mentioned justin time.

127
00:22:01.710 --> 00:22:02.880
Michael Shannon: Asset inventory.

128
00:22:03.990 --> 00:22:08.190
Michael Shannon: And it's the definitions on this slide the second bullet point.

129
00:22:11.280 --> 00:22:21.810
Michael Shannon: just in time is an inventory strategy us to increase efficiency and decrease waste by acquiring goods only as needed.

130
00:22:24.750 --> 00:22:25.260
Michael Shannon: and

131
00:22:26.490 --> 00:22:38.580
Michael Shannon: That just in time philosophy we're kind of suffering some of the consequences of that, as we have the supply chain disruptions suddenly.

132
00:22:39.660 --> 00:22:50.010
Michael Shannon: The acquiring of the goods right the acquiring of the goods as it's not as smooth and easy as it was two and a half years ago.

133
00:22:52.950 --> 00:23:06.150
Michael Shannon: So that may affect you know inventory and from a security standpoint, you know we're not really talking about you know, a retail grocery store we're talking about components.

134
00:23:07.350 --> 00:23:18.300
Michael Shannon: modular components that the this the hot spares the additional equipment that we need from a security standpoint.

135
00:23:24.240 --> 00:23:35.280
Michael Shannon: yeah Colin exactly now I allude to it, but by under no circumstances on this exam will that be like a scenario question.

136
00:23:38.880 --> 00:23:40.050
Michael Shannon: But you know.

137
00:23:41.070 --> 00:23:43.110
Michael Shannon: kind of theoretically absolutely.

138
00:23:46.200 --> 00:23:50.610
Michael Shannon: So you need to whatever your your fixed asset inventory.

139
00:23:52.590 --> 00:23:58.920
Michael Shannon: You have to realize that, obviously, this may be so massive that you have to scope this out.

140
00:23:59.670 --> 00:24:20.040
Michael Shannon: This needs to be a project or a program you using maybe an agile or P amp D project manager and you're not doing this, not an entire organization right you're you're taking off chunks you're biting off, you know, certain areas certain departments certain floors certain buildings.

141
00:24:22.590 --> 00:24:26.160
Michael Shannon: Certain cloud providers certain accounts okay.

142
00:24:28.110 --> 00:24:37.140
Michael Shannon: And again part of this creating this inventory is going forward trying to rely on automation as much as possible.

143
00:24:39.150 --> 00:25:00.330
Michael Shannon: And again, one of the main goals of this is not only to know what we have but one of the other benefits is will be doing an analysis to find will be called ghost it ghost assets shadow it right in this inventory will discover systems that are running you know Type two hypervisor.

144
00:25:01.410 --> 00:25:17.340
Michael Shannon: and possibly running unlicensed software or pirated content or unauthorized applications on the on all of our devices right, so you know there's plenty there's ghost it.

145
00:25:18.480 --> 00:25:22.050
Michael Shannon: In mobile application management as well right.

146
00:25:27.180 --> 00:25:35.400
Michael Shannon: I said I was going to move quickly to this, but you know, I have a difficult time, moving quickly, but I need to forget that I can't forget that you guys are not.

147
00:25:36.660 --> 00:25:55.080
Michael Shannon: Security plus people you're experienced so we talked about data roles owners steward custodian I guess I left one of them is also data processors that's a roll somebody who just you know does data input or runs batch files okay.

148
00:25:57.510 --> 00:26:12.210
Michael Shannon: The data life cycle is different, if you look at the CIS SP objectives, this is the data life cycle it's a different data life cycle than the cloud security professional.

149
00:26:13.500 --> 00:26:17.070
Michael Shannon: I actually prefer the cloud lifecycle better.

150
00:26:18.990 --> 00:26:37.500
Michael Shannon: This is the one that's presented in the objectives, so this is the life cycle, you really want to be familiar with okay so collection can be data creation data capture we acquire the data we do data entry we receive data okay.

151
00:26:38.850 --> 00:26:48.180
Michael Shannon: Maybe your CRM system is aggregating all of the different logs and alerts and alarms and traps and informs.

152
00:26:49.620 --> 00:26:52.650
Michael Shannon: You may have net flow collectors okay.

153
00:26:55.920 --> 00:27:04.530
Michael Shannon: So they have data collection, which is data creation data capture Okay, unless you.

154
00:27:05.550 --> 00:27:14.370
Michael Shannon: Create or gather the data it can't really go to the next phase and we talked about Article that's specifically the article 25.

155
00:27:16.500 --> 00:27:26.910
Michael Shannon: But in the gdpr it's really critical that in this these early phases that you're only generating creating collecting data that is going to be meaningful.

156
00:27:28.170 --> 00:27:37.560
Michael Shannon: that's the data minimization goal can be mentioned yesterday article 25 of gdpr companies must protect data by design.

157
00:27:38.820 --> 00:27:39.840
Michael Shannon: by default.

158
00:27:41.310 --> 00:27:49.050
Michael Shannon: Protecting data by deployment because you're deploying it into a secure environment is the least optimal.

159
00:27:52.920 --> 00:27:56.310
Michael Shannon: realize that you have different types of data storage.

160
00:27:57.480 --> 00:28:09.030
Michael Shannon: Will just use a cloud, for example, very common so at Amazon web services will just use them for an example, the object storage is will be called blob storage.

161
00:28:10.500 --> 00:28:14.430
Michael Shannon: object storage is not accessed through a file system.

162
00:28:15.450 --> 00:28:24.060
Michael Shannon: it's a flat hierarchy we access these buckets or containers of objects, and this is usually content.

163
00:28:25.350 --> 00:28:34.050
Michael Shannon: This is not stuff it's an object storage is not a highly transactional like you would see in block storage, it supports the database.

164
00:28:35.700 --> 00:28:40.320
Michael Shannon: A lot of random read writes high I OPS type of activity.

165
00:28:44.280 --> 00:28:54.990
Michael Shannon: high performance computing no object storage is there a store objects graphic files pictures audio files video files pdfs.

166
00:28:56.970 --> 00:29:03.600
Michael Shannon: The back end content for whatever your web application your content distribution.

167
00:29:04.800 --> 00:29:15.390
Michael Shannon: that's what object storage is and we access it primarily by two ways one through a URL or two through an API.

168
00:29:16.620 --> 00:29:20.520
Michael Shannon: And a cloud provider the API be sending like an endpoint.

169
00:29:22.380 --> 00:29:34.200
Michael Shannon: it's something that resides at the cloud provider you don't need a public IP address you don't need a gateway is just an endpoint connection the API call that you make to the object storage.

170
00:29:35.820 --> 00:29:36.270
Michael Shannon: Okay.

171
00:29:38.220 --> 00:29:39.870
Michael Shannon: massively scalable.

172
00:29:42.660 --> 00:29:46.860
Michael Shannon: Lots of metadata so with object storage, you can have version eating.

173
00:29:48.480 --> 00:29:56.040
Michael Shannon: lots of other types of metadata with those objects eXtensible metadata more analytics block storage.

174
00:29:56.370 --> 00:30:17.820
Michael Shannon: Again, is volume storage stored in a hard disk drive or a solid state drive or a raid array of those drives and it's you know zeros and ones and a fixed size volume accessed by some type of file system, maybe, if you if you're using you know, a storage area network type scenario.

175
00:30:18.900 --> 00:30:24.030
Michael Shannon: That control information, maybe IP based or layer two in the frame.

176
00:30:26.520 --> 00:30:37.200
Michael Shannon: If you access it over this storage area network, and you have various file systems that windows and Linux and MAC os use Okay, they have different use cases.

177
00:30:40.260 --> 00:30:44.160
Michael Shannon: So you need to be aware of how your data is being stored stored.

178
00:30:45.600 --> 00:30:56.670
Michael Shannon: there's different types of databases relational database systems and whether, if you migrate let's say your Oracle database up to the cloud.

179
00:30:57.540 --> 00:31:18.810
Michael Shannon: Usually, if you have a really extremely large Oracle database then it's going to involve several different services from the cloud provider you're probably going to get one of those direct connect connections that gives you 10 gig 50 gig and in some cities 100 gig pipe.

180
00:31:20.910 --> 00:31:30.450
Michael Shannon: you'll have some type of storage device like a gateway that you'll install on premises that will do a migration service.

181
00:31:31.830 --> 00:31:34.590
Michael Shannon: and other management services for you.

182
00:31:36.630 --> 00:31:40.260
Michael Shannon: And to get all that data, up to the data warehouse or the data lake.

183
00:31:41.280 --> 00:31:43.020
Michael Shannon: Which is a relational database system.

184
00:31:44.490 --> 00:31:56.940
Michael Shannon: Now do cloud providers have out of band ways to get data to the cloud they do have out of band methods like bell you can go and they'll ship you like a box.

185
00:31:57.660 --> 00:32:10.320
Michael Shannon: That holds like terabytes of data and it's encrypted and then you just ship it back or in some situations like aws has what's called the snowmobile with ocean, send a shipping container out.

186
00:32:12.030 --> 00:32:17.310
Michael Shannon: And you put a bunch of what are called snowballs on that thing and then you ship it back.

187
00:32:18.780 --> 00:32:25.350
Michael Shannon: For databases data storage data warehouse a key value database is no sql.

188
00:32:26.550 --> 00:32:33.960
Michael Shannon: Okay, no sequel document key value style high traffic web Apps E commerce systems gaming Apps.

189
00:32:35.010 --> 00:32:40.620
Michael Shannon: In memory that's mem cached and rattus type of storage.

190
00:32:42.090 --> 00:32:50.520
Michael Shannon: The document database is a key value type then there's other emerging newer types of databases that cloud providers offer.

191
00:32:50.940 --> 00:33:00.330
Michael Shannon: A graph database uses what are called nodes and graph databases excel at representing relationships.

192
00:33:01.140 --> 00:33:11.640
Michael Shannon: So graph databases are being used more and more for things like you know if a country is going to create a you know profile of their citizens.

193
00:33:12.270 --> 00:33:27.660
Michael Shannon: You know they'll use a graph database that will take all information about you and create this you know social profile recommendation engines fraud detection and then of course the ledger.

194
00:33:28.800 --> 00:33:33.780
Michael Shannon: ledger database is going to be involved with blockchain technology.

195
00:33:36.690 --> 00:33:44.460
Michael Shannon: On a blockchain You can write to the blockchain you can read from the blockchain database, but you can't change it.

196
00:33:45.870 --> 00:33:46.860
Michael Shannon: it's immutable.

197
00:33:48.030 --> 00:34:01.290
Michael Shannon: If you have to correct something it's going to be something you write on a subsequent change, but even if you write something or put in something that has a modification to that on a future block there has to be consensus.

198
00:34:02.820 --> 00:34:05.550
Michael Shannon: Some consensus mechanism approval.

199
00:34:06.630 --> 00:34:07.860
Michael Shannon: And it's distributed.

200
00:34:11.580 --> 00:34:30.360
Michael Shannon: So maintenance another phase Okay, this is basically once the data has been collected, where is it stored and maintenance also is going to involve processing, you know where where the raw data becomes information and information becomes knowledge.

201
00:34:31.620 --> 00:34:34.800
Michael Shannon: Moves movement integration data cleansing.

202
00:34:36.060 --> 00:34:39.900
Michael Shannon: augmentation you could even include token ization here.

203
00:34:41.730 --> 00:35:01.020
Michael Shannon: remnants is a term that means if you run some type of software some type of deletion process or cleaning process is something leftover maybe not the data, but is data about the data Meta data or some artifact does it remain.

204
00:35:02.310 --> 00:35:04.920
Michael Shannon: This is a known residual risk.

205
00:35:10.770 --> 00:35:13.500
Michael Shannon: Keeping data until it's no longer needed.

206
00:35:14.580 --> 00:35:36.000
Michael Shannon: that's what data retention is and that's going to be different for each data use case it'll be different if you're you know, subject to some regulations or mandates, you have to keep your corporate tax records for a certain number of years if you're an insurance company, even if a.

207
00:35:37.320 --> 00:35:51.660
Michael Shannon: You have a client of your insurance company they switch to another ensure which happens all the time you slept to maintain that data about that customer for a certain period of time.

208
00:35:53.580 --> 00:36:03.210
Michael Shannon: So the type of organization you're in business sector regulations mandate that's going to dictate your data retention policy.

209
00:36:04.320 --> 00:36:05.640
Michael Shannon: Your archival.

210
00:36:07.080 --> 00:36:10.020
Michael Shannon: And then there is the disposal once that.

211
00:36:11.550 --> 00:36:14.100
Michael Shannon: you've gone past the retention period.

212
00:36:15.270 --> 00:36:27.780
Michael Shannon: Or you don't have to retain the data, this is the disposition the disposal phase phase we're not just talking about you know wiping or deleting zeros and ones.

213
00:36:28.950 --> 00:36:45.300
Michael Shannon: You know there's physical assets, a lot of organizations, a big vulnerability is that they will just take hard drives they'll take components from laptops and phones and they just throw them in the dumpster.

214
00:36:48.570 --> 00:36:52.140
Michael Shannon: that's not that's a dumpster diving that's gold.

215
00:36:53.340 --> 00:37:00.660
Michael Shannon: You know if you can find if you're doing dumpster diving is social engineering and you can find these drives and other things are just tossed.

216
00:37:02.220 --> 00:37:03.240
Michael Shannon: Man that's.

217
00:37:04.260 --> 00:37:06.930
Michael Shannon: that's a that's a that's a huge find.

218
00:37:11.430 --> 00:37:17.190
Michael Shannon: We have to consider any type of archival and media storage how we're going to dispose of that.

219
00:37:18.540 --> 00:37:19.200
Michael Shannon: So.

220
00:37:20.880 --> 00:37:27.960
Michael Shannon: there's burning okay burning a lot of I don't I wouldn't say a lot but i've worked for companies that have a furnace.

221
00:37:29.010 --> 00:37:37.470
Michael Shannon: When you go down to the basement and you have a furnace and you just throw it so stuff in there pumping is better than shredding.

222
00:37:38.130 --> 00:37:49.950
Michael Shannon: Because, as we know, if you shred documents and you keep them bundled together that they can be you know you can you know reform them.

223
00:37:50.820 --> 00:38:01.230
Michael Shannon: And it's true it's time consuming, but it can be done, I mean we see it in movies and TV shows all the time, but you know pumping and pulverizing paper records.

224
00:38:02.070 --> 00:38:14.160
Michael Shannon: The more destruction, you can do the better obviously you want it to you want it to be rendered in some type of form that just can't be you know re compiled.

225
00:38:15.330 --> 00:38:18.900
Michael Shannon: d causing cutting up DVDs.

226
00:38:20.070 --> 00:38:22.800
Michael Shannon: democratizing magnet tapes you know.

227
00:38:24.060 --> 00:38:25.410
Michael Shannon: I live in Texas.

228
00:38:27.000 --> 00:38:27.840
Michael Shannon: So you know.

229
00:38:29.130 --> 00:38:38.280
Michael Shannon: I would be lying to say there have not been times, where i've taken my hard drives or whatever out to the country.

230
00:38:40.440 --> 00:38:41.310
Michael Shannon: And you know.

231
00:38:43.260 --> 00:38:46.320
Michael Shannon: Practice my pistol okay so.

232
00:38:47.550 --> 00:38:55.170
Michael Shannon: there's that there's that physical destruction, however, you do it Sledgehammer okay pulverizes.

233
00:38:57.540 --> 00:39:02.430
Michael Shannon: So these are grant this is very kind of granular security plus stuff but.

234
00:39:03.600 --> 00:39:04.770
Michael Shannon: data retention.

235
00:39:06.570 --> 00:39:10.380
Michael Shannon: Well Giuseppe, let me say this here's how they're related.

236
00:39:12.120 --> 00:39:13.920
Michael Shannon: You should only be retaining.

237
00:39:15.900 --> 00:39:18.990
Michael Shannon: data that has that has that you've minimized.

238
00:39:20.130 --> 00:39:40.050
Michael Shannon: Right so part of retention is, we would only retain data that's meaningful now if it's something that we have to maintain a read retain as for governance or regulations or for legal reasons, like like corporate tax records and those types of things.

239
00:39:41.610 --> 00:39:48.600
Michael Shannon: But again, you should only be retaining the data that has been a result of your data minimization.

240
00:39:49.950 --> 00:39:54.270
Michael Shannon: In other words, you don't want to archive and retaining a bunch of meaningless data.

241
00:39:56.040 --> 00:40:00.540
Michael Shannon: Because there's a concept of of data.

242
00:40:01.800 --> 00:40:04.530
Michael Shannon: Whenever we introduce mechanisms.

243
00:40:05.790 --> 00:40:06.360
Michael Shannon: For.

244
00:40:07.770 --> 00:40:24.750
Michael Shannon: obfuscation of our data or methods that are going to mask or make the data anonymous you following me, maybe because it's intellectual property or it's personal health whatever we use methods to obfuscate.

245
00:40:25.890 --> 00:40:40.380
Michael Shannon: You know, we mask out certain numbers, whatever we do, we have to make sure that whatever methods we're using you the attacker cannot use what's called an inferior.

246
00:40:41.760 --> 00:40:53.760
Michael Shannon: inference okay sorry about that inference, in other words, whatever you have not mast whatever you've not made anonymous whatever you not have these stated.

247
00:40:55.470 --> 00:41:05.790
Michael Shannon: They the attacker can infer from what's left over information either that data itself or better data of that data.

248
00:41:07.020 --> 00:41:10.800
Michael Shannon: So, even so, one of the other risks of storing.

249
00:41:12.180 --> 00:41:26.550
Michael Shannon: or retaining data that really defies minimization it's not really necessary data it's not meaningful necessarily but but inference can be made from that raw data we don't want that to happen.

250
00:41:28.290 --> 00:41:41.040
Michael Shannon: Okay, so so once we get through the process of knowing what we have that's really the first step of what we would call, generally speaking, risk management and risk assessment.

251
00:41:42.870 --> 00:41:58.650
Michael Shannon: The first phase, as I said, like the insurance example I use you're going to get a home insurance policy, you have to know what you have and and have some type of value and along with that we have labeling tagging.

252
00:41:59.790 --> 00:42:06.030
Michael Shannon: Classification sensitivity, all those wonderful things that we've spent the first 45 minutes talking about.

253
00:42:07.920 --> 00:42:13.320
Michael Shannon: never talk about risk and, basically, that is why we are here.

254
00:42:14.820 --> 00:42:36.600
Michael Shannon: That is, you know, one of our main goals, not necessarily to be you know in charge of the risk analysis and risk management that can involve a wide variety of parties, but we have a huge role to play in managing risk as security practitioners architects engineers administrators.

255
00:42:38.640 --> 00:42:40.290
Michael Shannon: So where you are now.

256
00:42:42.360 --> 00:42:44.040
Michael Shannon: Where you exist right now.

257
00:42:45.930 --> 00:42:54.630
Michael Shannon: that's your inherent risk okay your baseline the natural level of risk that you have right now.

258
00:42:56.580 --> 00:42:58.020
Michael Shannon: The current risk level.

259
00:42:59.070 --> 00:43:08.010
Michael Shannon: Given what you have in place your existing technical controls your administrative and your physical controls.

260
00:43:09.120 --> 00:43:13.710
Michael Shannon: that's inherent risk okay that's your status quo.

261
00:43:14.790 --> 00:43:34.440
Michael Shannon: residual risk is what's left over after you introduce controls, now I if you if you look at this from the standpoint of like open, fair factor analysis of information risk what they would say is residual risk is what's left over.

262
00:43:35.490 --> 00:43:50.580
Michael Shannon: after you have introduced and raised the level of difficulty or resistance through controls, but you've raised the level of difficulty or resistance to the threat actors and threat agents.

263
00:43:51.750 --> 00:43:52.410
Michael Shannon: is how they would.

264
00:43:54.330 --> 00:43:55.230
Michael Shannon: describe this.

265
00:43:56.880 --> 00:44:01.620
Michael Shannon: Now here's the point is residual risk bad no.

266
00:44:02.640 --> 00:44:28.080
Michael Shannon: As long as the residual risk is acceptable, based on your risk tolerance risk handling also referred to as your risk appetite, and this is not just one metric this is, you know, based on a wide variety of assets and asset classes and scenarios it's not a one size fits all.

267
00:44:30.060 --> 00:44:36.420
Michael Shannon: And it's things like the risk ledger and risk register that needs to store.

268
00:44:38.100 --> 00:44:47.250
Michael Shannon: The results of this analysis that tells us what is our residual risk, and it needs to be acceptable, based on how we treat her handle risk.

269
00:44:49.050 --> 00:44:57.630
Michael Shannon: Now, on the exam you want to think about this from a security manager standpoint so what's going to come into play who's just going to come into play.

270
00:44:57.990 --> 00:45:05.880
Michael Shannon: And i'm not memorizing these and getting a question on you know what is risk avoidance, let me give you an example.

271
00:45:06.720 --> 00:45:23.160
Michael Shannon: let's let's look at a risk it's a risk acceptance, let me start there so you're going to accept or tolerate tolerate the level of risk you're deciding not to introduce a countermeasure control okay.

272
00:45:24.210 --> 00:45:36.900
Michael Shannon: Well that's fine the definition is fine, but, but how does that really apply to us as security managers on this exam well here's how it applies if you or your team makes a decision that you're that a risk is acceptable.

273
00:45:38.130 --> 00:45:58.920
Michael Shannon: You know the data that you store at the cloud in the different regions where it is or whatever you've decided to use for your disaster recovery site is acceptable you're going to have to most likely justify that decision to a steering committee or a security team or the C suite.

274
00:46:00.450 --> 00:46:11.970
Michael Shannon: So, from a security management standpoint, the responsibility is it goes beyond just do we decide to accept it, based on qualitative and quantitative analysis it's.

275
00:46:12.720 --> 00:46:26.280
Michael Shannon: We have to make sure that we're able to justify accepting the risk or avoiding the risk and justify the resources we're asking for to reduce or mitigate risk.

276
00:46:29.070 --> 00:46:37.530
Michael Shannon: and to be able to justify the resources we asked for from the Steering Committee or the C suite or the CIS, or whoever.

277
00:46:39.480 --> 00:46:45.720
Michael Shannon: Usually today a qualitative reporting is not going to be enough.

278
00:46:47.010 --> 00:46:57.780
Michael Shannon: going in and saying I need $50,000 because i've got this list I made up of really bad things that can happen, and like i've got on a scale of one to 10, what are the worst.

279
00:47:00.180 --> 00:47:09.900
Michael Shannon: Today, before a decision maker, is going to write the check or approve the budget, they would rather see something that's more quantitative.

280
00:47:11.640 --> 00:47:12.390
Michael Shannon: Preferably.

281
00:47:14.160 --> 00:47:21.510
Michael Shannon: So that's the way we think about this from the exam standpoint not memorizing the four ways to treat risk.

282
00:47:22.620 --> 00:47:37.290
Michael Shannon: you're expected to know that, with a security plus certification or the SS CP now another decision from a management standpoint would be risks transference or sharing those kind of scenarios right so.

283
00:47:38.370 --> 00:47:45.180
Michael Shannon: Using the cloud provider is a way to transfer share risk because there is a shared responsibility model.

284
00:47:46.680 --> 00:47:50.460
Michael Shannon: And it depends on the type of service.

285
00:47:51.810 --> 00:48:02.730
Michael Shannon: If its infrastructure as a service where i'm basically just using their data centers but i'm the one that decides to bring up whatever operating systems and applications and platforms.

286
00:48:04.920 --> 00:48:23.340
Michael Shannon: i'm running the database on those operating systems well i'm assuming more risk in that scenario, if I decide to pay them for a relational database service like a fully managed my sequel service they're going to provide the underlying servers.

287
00:48:25.470 --> 00:48:34.680
Michael Shannon: they'll do the updates to my sequel or Oracle or whatever if i'm paying them for that managed service they're going to assume more responsibility.

288
00:48:36.990 --> 00:48:53.730
Michael Shannon: we'll talk more about that, when we get to cloud, but other examples are like you know, insurance and insurance policy is risk transference a cyber currency or not type of currency, a cyber security writer or a denim dear policy.

289
00:48:56.730 --> 00:49:08.940
Michael Shannon: I talked yesterday about the possibility of having an agreement with another organization that's quite a few miles away in a metropolitan area and we're going to have a shared cold or warm site.

290
00:49:10.740 --> 00:49:16.320
Michael Shannon: that's transference of risk which by the way, you probably have to justify that as well.

291
00:49:19.200 --> 00:49:27.540
Michael Shannon: So remember we're going beyond just do I know the four types of risk treatment, we have to think about it from a security manager standpoint.

292
00:49:30.060 --> 00:49:39.720
Michael Shannon: When assessing the vulnerability of your organization or your whatever the scope your department your business unit your floor your building whatever.

293
00:49:41.310 --> 00:49:44.580
Michael Shannon: It all begins with how you define vulnerability.

294
00:49:47.370 --> 00:49:54.030
Michael Shannon: And again, like I said vulnerability really shouldn't be like a laundry list of bad things that can happen.

295
00:49:55.710 --> 00:49:57.150
Michael Shannon: You have to introduce.

296
00:49:59.070 --> 00:50:06.120
Michael Shannon: The risk components to vulnerability, in other words magnitude and impact.

297
00:50:07.320 --> 00:50:09.240
Michael Shannon: likelihood and probability.

298
00:50:10.470 --> 00:50:27.150
Michael Shannon: And by the way over some type of timeframe, a quarter a fiscal year an annual year usually to define a risk and vulnerability, we need at least those three variables what's the magnitude or impact.

299
00:50:28.320 --> 00:50:30.240
Michael Shannon: what's the probability or likelihood.

300
00:50:31.410 --> 00:50:32.940
Michael Shannon: And then over a timeframe.

301
00:50:34.230 --> 00:50:39.330
Michael Shannon: And then we can, if we if we need to we can start to break things down and decompose it.

302
00:50:41.220 --> 00:50:50.640
Michael Shannon: To get more accurate metrics, which is something that fair factor analysis of information risk excels at.

303
00:50:55.230 --> 00:51:03.390
Michael Shannon: So the more quantitative we can make this for our decision makers and the steering committee really the better off.

304
00:51:04.500 --> 00:51:07.590
Michael Shannon: Okay there's been a number of books.

305
00:51:08.880 --> 00:51:10.770
Michael Shannon: But it's pretty much been proven.

306
00:51:12.300 --> 00:51:14.040
Michael Shannon: By people like Douglas hubbard.

307
00:51:15.270 --> 00:51:18.930
Michael Shannon: who's written several books he's he's part of the open, fair.

308
00:51:21.270 --> 00:51:27.180
Michael Shannon: But he's they pretty much proven the ineffectiveness of qualitative risk analysis.

309
00:51:28.410 --> 00:51:32.280
Michael Shannon: that's what has been used traditionally now on this exam.

310
00:51:33.480 --> 00:51:36.390
Michael Shannon: you're not you're not there to to.

311
00:51:37.530 --> 00:51:38.820
Michael Shannon: To take a stand.

312
00:51:41.010 --> 00:51:53.070
Michael Shannon: it's not going to be a matter of one is better than the other, we need to understand, both because qualitative still has a lot of value, especially the more macro the analysis.

313
00:51:54.540 --> 00:52:02.280
Michael Shannon: If you're making large corporate governance decisions often all you can do is qualitative analysis.

314
00:52:03.750 --> 00:52:10.290
Michael Shannon: So this is not an either or thing that they're going to ask you to you know, take a side.

315
00:52:12.960 --> 00:52:25.890
Michael Shannon: But again before you can assess vulnerability, as this slide is saying you have to know what you have and know what your controls are, in other words, you have to know what your inherent risk is okay.

316
00:52:28.620 --> 00:52:39.540
Michael Shannon: Another term that comes up as far as assessing vulnerability is you're looking for indicators of compromise now often we can look for these.

317
00:52:40.050 --> 00:52:53.070
Michael Shannon: Through a wide variety of mechanisms, we can look at these two vulnerability look for these two vulnerability assessment tools we can look at look for these through threat hunting penetration testing.

318
00:52:54.510 --> 00:52:58.950
Michael Shannon: Okay, but an indicator of compromise is a term you need to be able to define.

319
00:53:00.990 --> 00:53:02.130
Michael Shannon: Because they represent.

320
00:53:04.110 --> 00:53:12.900
Michael Shannon: Existing vulnerabilities and these indicators of compromise can be something that's been on a system for a long period of time.

321
00:53:14.460 --> 00:53:23.040
Michael Shannon: Doing key logging or capturing a webcam or X will trading data.

322
00:53:24.510 --> 00:53:29.100
Michael Shannon: or cyber currency mining crypto jacking.

323
00:53:31.080 --> 00:53:39.210
Michael Shannon: And you don't you don't know it until the audit or the investigation or the penetration test.

324
00:53:40.500 --> 00:53:46.350
Michael Shannon: So these are network or host based cyber observe cyber miserables.

325
00:53:47.700 --> 00:53:53.850
Michael Shannon: That can be considered forensic artifacts things you would look for in a forensic investigation.

326
00:53:55.200 --> 00:53:58.020
Michael Shannon: registry entries configuration files.

327
00:53:59.160 --> 00:54:03.480
Michael Shannon: unknown files that you don't know the disposition of the file.

328
00:54:04.620 --> 00:54:11.700
Michael Shannon: Something that has been compressed maybe a bunch of ar ar files in a deep in your directory structure.

329
00:54:13.080 --> 00:54:21.270
Michael Shannon: encrypted files things that are in swap space or slack space on a drive resident in memory.

330
00:54:25.860 --> 00:54:26.490
Michael Shannon: So.

331
00:54:27.690 --> 00:54:32.070
Michael Shannon: information gathering is really the first phase of vulnerability assessment.

332
00:54:33.180 --> 00:54:37.680
Michael Shannon: We have you know, the ability to get a wide variety of logs.

333
00:54:38.700 --> 00:54:59.100
Michael Shannon: Traditional you know management V lands would have multiple servers that are collecting different logs you know your Microsoft servers that has the system application security logs firewalls generate logs ids devices ips devices.

334
00:55:00.510 --> 00:55:02.580
Michael Shannon: You have SNP traps.

335
00:55:04.290 --> 00:55:12.540
Michael Shannon: If you're using SNP version to see still, you have the vulnerability of using Community strings.

336
00:55:14.010 --> 00:55:17.520
Michael Shannon: Preferably you're using SNP version three.

337
00:55:18.570 --> 00:55:21.420
Michael Shannon: which gives you the same services as IP SEC.

338
00:55:22.740 --> 00:55:24.450
Michael Shannon: You have net flow collectors.

339
00:55:25.680 --> 00:55:43.530
Michael Shannon: version five is going to collect records that basically map to tcp UDP IP icmp headers but net flow version nine is eXtensible it's xml based so you can create your own custom tags and schema.

340
00:55:46.590 --> 00:55:58.140
Michael Shannon: Often the various logs and traps and informs and output are being sent to a theme system security information and event management system.

341
00:55:59.520 --> 00:56:01.740
Michael Shannon: combination of hardware and software.

342
00:56:02.820 --> 00:56:04.110
Michael Shannon: could be cloud based.

343
00:56:05.700 --> 00:56:06.300
Michael Shannon: You know.

344
00:56:08.820 --> 00:56:11.880
Michael Shannon: Like I mentioned azure has Sentinel.

345
00:56:18.390 --> 00:56:24.420
Michael Shannon: Next Generation we're going to talk about all these things so again vulnerability assessment involves tools right.

346
00:56:25.470 --> 00:56:33.840
Michael Shannon: there's also vulnerability databases, you can take advantage of you can leverage right the national vulnerability database.

347
00:56:34.920 --> 00:56:37.410
Michael Shannon: You can other sites vendors.

348
00:56:38.610 --> 00:56:41.940
Michael Shannon: You know sands.org Cisco.

349
00:56:44.010 --> 00:57:05.460
Michael Shannon: there's the common vulnerabilities and exposures, often in our CIS SP bootcamp i'll have people from miter.org it's not a it's not rare usually in each boot camp, I do, I have a handful of people that are from miter.

350
00:57:06.480 --> 00:57:17.790
Michael Shannon: So you know the cbe an ID number description public references cross references used by the national vulnerability database that's missed.

351
00:57:18.660 --> 00:57:31.980
Michael Shannon: The mist and vd and there's a scoring system and, often, for example, the scoring system, and these updates your in your security operations Center the tools that you're using are integrated.

352
00:57:33.060 --> 00:57:38.460
Michael Shannon: So you're getting feeds you're getting updates okay.

353
00:57:41.850 --> 00:57:42.750
Michael Shannon: So there's.

354
00:57:44.760 --> 00:57:56.010
Michael Shannon: I the ISS exports database today, and these are not things to be specifically tested on but you should be familiar with them and if you're not, this is a gap analysis.

355
00:57:58.590 --> 00:58:02.580
Michael Shannon: Go check it out and see what the what they what they providing.

356
00:58:05.820 --> 00:58:14.640
Michael Shannon: and doing vulnerability scanning that is usually something that's part of a vulnerability tester assessment that is usually scheduled.

357
00:58:16.020 --> 00:58:29.250
Michael Shannon: Okay, now, can you do a manual vulnerability scanning where you're maybe in real time tweaking some type of script or maybe you're in real time writing Python.

358
00:58:29.910 --> 00:58:44.070
Michael Shannon: That might be more part of a penetration test technically a vulnerability scanning process is something that's scheduled using like burp suite burp suite or oh wasps zap.

359
00:58:46.050 --> 00:58:51.720
Michael Shannon: automated tools that are looking for vulnerabilities on websites and web applications.

360
00:58:53.100 --> 00:59:04.470
Michael Shannon: vulnerabilities that cross site scripting and different variants there's like three or four variants of cross site scripting request forgery which compromises authenticated sessions.

361
00:59:04.980 --> 00:59:15.330
Michael Shannon: If you're using sequel as your back end database to the web service or you're using some database that accepts structured query language.

362
00:59:15.960 --> 00:59:27.540
Michael Shannon: there's different types of injection attacks sequel injection l dap injection so vulnerability scanning tools vulnerability scanning usually something that's more scheduled.

363
00:59:28.920 --> 00:59:42.180
Michael Shannon: We always have to be cognizant of the fact that we have privileged insiders that may be involved in the dark web, so the dark web is an issue for us.

364
00:59:43.560 --> 00:59:52.920
Michael Shannon: From the standpoint of do we have privileged insiders who are using the dark dark web or at a cloud provider.

365
00:59:54.450 --> 01:00:08.280
Michael Shannon: there's exit nodes they may be, attacking our cloud resources, a dark web is also called an overlay network or or dark net it's called bad because it's not indexed by the.

366
01:00:10.320 --> 01:00:12.360
Michael Shannon: World Wide Web search engines.

367
01:00:14.310 --> 01:00:28.200
Michael Shannon: We often think of the dark web is kind of like a James Bond movie right where there's some island out in the Pacific, where some bad evil person has really powerful computers well.

368
01:00:30.030 --> 01:00:31.530
Michael Shannon: that's not what the dark web is.

369
01:00:33.210 --> 01:00:44.100
Michael Shannon: But you need special software and browsers it's it's you know it's highly distributed with peer to peer file sharing, so you can use TOR or freenet or riffle.

370
01:00:44.670 --> 01:00:53.220
Michael Shannon: to access the dark web, why is this something to be cognizant of from a vulnerability standpoint well there's a lot of bad stuff there.

371
01:00:55.350 --> 01:00:57.600
Michael Shannon: And if you're going to be involved in forensics.

372
01:00:59.640 --> 01:01:15.870
Michael Shannon: forensic you know cyber forensics if that's what you're doing now, then you know what i'm talking you'll know what i'm talking about, but if moving forward you're going to get more involved in cyber forensics over half of your activities will be involving child pornography.

373
01:01:17.400 --> 01:01:20.010
Michael Shannon: it's just a sad sad truth.

374
01:01:21.750 --> 01:01:26.250
Michael Shannon: And that is can be regularly found on the dark Web.

375
01:01:27.300 --> 01:01:32.700
Michael Shannon: And you're not necessarily forensic investigating because you have an employee.

376
01:01:34.050 --> 01:01:45.840
Michael Shannon: And it may be the case where they're engaged in that, but often that is used as a payload to get on the system of somebody in the C suite of the C team or a whale.

377
01:01:47.130 --> 01:01:48.540
Michael Shannon: And then to extort them.

378
01:01:50.070 --> 01:01:54.270
Michael Shannon: And because you know, the better the the the bigger their reputation.

379
01:01:55.830 --> 01:02:06.090
Michael Shannon: You know in society in their religious affiliation, the more likely they are to pay off an extortion, or a ransom.

380
01:02:09.390 --> 01:02:14.100
Michael Shannon: Another thing about the dark web is that it has malware as a service.

381
01:02:15.240 --> 01:02:29.700
Michael Shannon: Which is a cottage industry, you know a lot of people who can't find a job will just now go into the dark web and scrape up some money and pay for a ransomware campaign.

382
01:02:30.960 --> 01:02:45.450
Michael Shannon: And then the malware as a service entity will run the campaign will will even do like customer service to help that target go get my narrow or whatever to pay off the ransom.

383
01:02:51.000 --> 01:02:56.280
Michael Shannon: Often, when you're doing it, for example, a penetration test or a vulnerability assessment.

384
01:02:57.480 --> 01:03:07.530
Michael Shannon: If somebody is running a campaign against your organization often they will use Open Source intelligence sources.

385
01:03:08.370 --> 01:03:15.870
Michael Shannon: or tools there's tools, you can get an exploit kits like melty go that are graphical representations.

386
01:03:16.260 --> 01:03:32.520
Michael Shannon: And it's similar to that to the goal of like a graph database that I mentioned that uses nodes to create relationships you're doing the same type of thing about an entity with these tools scraping everything you can find.

387
01:03:33.900 --> 01:03:49.350
Michael Shannon: And this is used for reconnaissance information gathering the early phases of an advanced persistent threat or a campaign against your organization or as we'll see when we're doing some someone's doing a penetration test.

388
01:03:50.730 --> 01:03:59.550
Michael Shannon: we've hired some firm to do pen testing and we're going to pay them extra to do a black box, where they don't know anything about us.

389
01:04:00.330 --> 01:04:12.990
Michael Shannon: it's going to be more costly but they're going to spend time using open source intelligence tools and other threat intelligence sources in the early reconnaissance phase and information gathering.

390
01:04:17.730 --> 01:04:21.600
Michael Shannon: This is these sources are kind of US centric.

391
01:04:22.890 --> 01:04:35.610
Michael Shannon: Because they involve the cyber security and infrastructure security agency also mitre that we talked about, and this these.

392
01:04:38.130 --> 01:04:52.800
Michael Shannon: types of sources really started to come together at like 20 years ago okay after 911 right, so there was there was lessons learned and one of the lessons that was learned was that.

393
01:04:53.850 --> 01:04:56.100
Michael Shannon: that the Federal agencies.

394
01:04:57.300 --> 01:05:11.820
Michael Shannon: Okay, regardless of what their role or role is or was were very siloed and there was just not enough cooperation and communication inter agency.

395
01:05:13.110 --> 01:05:31.830
Michael Shannon: Okay, where this law enforcement, whether it's intelligence, whatever, and so one of the things that emerged from that is having exchange of real time information and metadata that can be used by multiple entities.

396
01:05:32.970 --> 01:05:59.220
Michael Shannon: So that became a huge initiative right so automated indicator sharing is that type of database with a wide variety of participants, public and private sector sticks is a language that was created by mitre a standardized language with structured information about cyber threats OK.

397
01:06:00.360 --> 01:06:20.820
Michael Shannon: And then taxi is the transport mechanism that's easy to remember Okay, because a taxi right http https based primarily and then you have other types of tools that use machine learning predictive analysis, you know predictive analysis.

398
01:06:22.140 --> 01:06:23.190
Michael Shannon: That is.

399
01:06:24.780 --> 01:06:35.460
Michael Shannon: sounds futuristic but the concepts behind the movie minority report which i'm sure some of you have seen, but even if you haven't.

400
01:06:36.240 --> 01:06:59.520
Michael Shannon: Remember, for those who've seen in if you haven't seen it it's built around a future time where possibly using graph databases, you will predict, who is more likely to commit crimes pre crime that's not that's not a science fiction anymore.

401
01:07:01.530 --> 01:07:07.470
Michael Shannon: it's happening predictive analysis artificial intelligence involved in these processes.

402
01:07:09.090 --> 01:07:28.950
Michael Shannon: So you have to document all this right and again we talked about one of the main areas we use is what's called a a risk ledger or a risk register a risk log could be you know spreadsheets spreadsheets and databases, but you've got to have something.

403
01:07:30.090 --> 01:07:36.270
Michael Shannon: This is nice, this is from this is from a ready.gov so you know.

404
01:07:37.950 --> 01:07:42.840
Michael Shannon: Identifying your hazards and again what part of your job is understanding.

405
01:07:44.370 --> 01:08:03.870
Michael Shannon: The probability and likelihood now again, you can you can approach the hazards saying you know, on a scale of one to 10 will have a fire on a scale of one to 10 will have a mechanical breakdown, but usually we want to shoot for something more quiet.

406
01:08:06.240 --> 01:08:12.300
Michael Shannon: And something that you didn't think was a you know, a clear and present danger.

407
01:08:13.650 --> 01:08:26.430
Michael Shannon: Suddenly, out of nowhere, it becomes a clear and present danger, I mean there was a lot of organizations many across the planet that were not ready for the impact of that.

408
01:08:29.040 --> 01:08:29.490
Michael Shannon: Right.

409
01:08:30.810 --> 01:08:32.790
Michael Shannon: Now, maybe we weren't surprised.

410
01:08:34.140 --> 01:08:36.600
Michael Shannon: But we were surprised by the reaction.

411
01:08:37.800 --> 01:08:39.240
Michael Shannon: by governments.

412
01:08:41.310 --> 01:08:51.930
Michael Shannon: So obviously you have to have some flexibility built in, but understanding the potential possible hazards and you know once things happen.

413
01:08:53.910 --> 01:09:01.200
Michael Shannon: and your organization goes through that well that that's obviously going to change your risk management.

414
01:09:02.310 --> 01:09:05.160
Michael Shannon: You know more and more organizations will be prepared.

415
01:09:08.940 --> 01:09:18.720
Michael Shannon: And then the assets definitely have to know that, and at the top of the list for many organizations, people are the most valuable asset but that's not always the case.

416
01:09:19.740 --> 01:09:24.810
Michael Shannon: In some organizations, it may be the facility, the equipment, the data.

417
01:09:26.550 --> 01:09:35.130
Michael Shannon: Okay, our corporate secrets are formulas and then analyzing the impact okay magnitude so.

418
01:09:37.290 --> 01:09:38.280
Michael Shannon: some type of.

419
01:09:40.320 --> 01:09:41.310
Michael Shannon: ledger's and.

420
01:09:42.390 --> 01:09:48.780
Michael Shannon: A combination of ledger's and matrices This is one that comes from a guy at Intel.

421
01:09:49.920 --> 01:09:58.740
Michael Shannon: And really you know, being aware of kind of these different types of events, I remember a negative event is an incident.

422
01:09:59.250 --> 01:10:23.850
Michael Shannon: Can I kind of be generally aware of those is is good, you know it's common sense that's good to know know, knowing that you can have non hostile actors and hostile actors, but the big takeaway here is, you know who checks off all the boxes, according to this security analyst at Intel.

423
01:10:25.050 --> 01:10:27.030
Michael Shannon: But like I said I don't like this word.

424
01:10:29.190 --> 01:10:30.480
Michael Shannon: I like compromised.

425
01:10:31.980 --> 01:10:38.820
Michael Shannon: compromised insider who may be disgruntled but we talked about that yesterday checks off all the boxes.

426
01:10:46.860 --> 01:10:47.820
Michael Shannon: All right, we're doing good.

427
01:10:49.830 --> 01:10:52.890
Michael Shannon: Even though I can't move my slides forward so.

428
01:10:55.230 --> 01:11:00.840
Michael Shannon: I want to take my break now because I don't want to I don't want to talk for five minutes and then take a break, this is a whole.

429
01:11:01.380 --> 01:11:10.410
Michael Shannon: we're into a new topic here okay so we're going to come back and we're going to talk about and compare qualitative semi Croissant.

430
01:11:11.280 --> 01:11:24.120
Michael Shannon: And quantitative analysis Okay, and then give you some places to run with if you need to do some gap analysis here okay so let's go and take our first break now and i'll see you back here i'm going to stop the recording.

431
01:11:26.040 --> 01:11:28.020
Michael Shannon: We don't want that, on the playback.

